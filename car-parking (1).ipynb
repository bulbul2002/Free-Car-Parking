{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Reference-https://towardsdatascience.com/implementing-alexnet-cnn-architecture-using-tensorflow-2-0-and-keras-2113e090ad98","metadata":{}},{"cell_type":"markdown","source":"# Importing packages and libraries","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np # linear algebra #rgb values for images exist in a np array\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport PIL # Importing Image class from PIL module\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nimport cv2\n#import time\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\n#from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-02T15:36:21.891993Z","iopub.execute_input":"2022-05-02T15:36:21.894135Z","iopub.status.idle":"2022-05-02T15:36:28.31773Z","shell.execute_reply.started":"2022-05-02T15:36:21.893999Z","shell.execute_reply":"2022-05-02T15:36:28.316975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"data_path = \"/kaggle/input/find-a-car-park/data/\"\nCategories = [\"Free\", \"Full\"]\nimg_size = 150\n","metadata":{"execution":{"iopub.status.busy":"2022-05-02T15:36:28.319315Z","iopub.execute_input":"2022-05-02T15:36:28.319531Z","iopub.status.idle":"2022-05-02T15:36:28.325686Z","shell.execute_reply.started":"2022-05-02T15:36:28.319504Z","shell.execute_reply":"2022-05-02T15:36:28.324893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = []\n\ndef create_data():    \n    for category in Categories:\n        path = os.path.join(data_path,category)\n        class_num = Categories.index(category)\n        print(path) #lepath to each category file\n        for img in os.listdir(path):\n            print(img) #path to each image in the category files\n            img_arr = cv2.imread(os.path.join(path,img))\n            new_img_arr = cv2.resize(img_arr,(img_size,img_size))\n            data.append([new_img_arr,class_num])\ncreate_data()   ","metadata":{"scrolled":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-02T15:36:28.326803Z","iopub.execute_input":"2022-05-02T15:36:28.327433Z","iopub.status.idle":"2022-05-02T15:38:39.667981Z","shell.execute_reply.started":"2022-05-02T15:36:28.327391Z","shell.execute_reply":"2022-05-02T15:38:39.667039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(data))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T15:38:39.669276Z","iopub.execute_input":"2022-05-02T15:38:39.670554Z","iopub.status.idle":"2022-05-02T15:38:39.677634Z","shell.execute_reply.started":"2022-05-02T15:38:39.670501Z","shell.execute_reply":"2022-05-02T15:38:39.676547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X= [] #store images\nY= [] #store lables[\"free\",\"full\"]","metadata":{"execution":{"iopub.status.busy":"2022-05-02T15:38:39.679314Z","iopub.execute_input":"2022-05-02T15:38:39.679536Z","iopub.status.idle":"2022-05-02T15:38:39.687746Z","shell.execute_reply.started":"2022-05-02T15:38:39.679509Z","shell.execute_reply":"2022-05-02T15:38:39.686751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for features, labels in data:\n    X.append(features)\n    Y.append(labels)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-02T15:38:39.688781Z","iopub.execute_input":"2022-05-02T15:38:39.689412Z","iopub.status.idle":"2022-05-02T15:38:39.700634Z","shell.execute_reply.started":"2022-05-02T15:38:39.689367Z","shell.execute_reply":"2022-05-02T15:38:39.699736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Each Images is stored in terms of its RGB values in an array","metadata":{}},{"cell_type":"code","source":"X[0]","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-02T15:38:39.702163Z","iopub.execute_input":"2022-05-02T15:38:39.702377Z","iopub.status.idle":"2022-05-02T15:38:39.717961Z","shell.execute_reply.started":"2022-05-02T15:38:39.702354Z","shell.execute_reply":"2022-05-02T15:38:39.717032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting data into training and testting dataset","metadata":{}},{"cell_type":"code","source":"# separate data\n#training data - 80% of data\n#testing data - 20% of data\n#random_state is used to get the same split everytime. If we do not fix it, it would result in a different split everytme the code is run\nx_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.20,random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-02T15:38:39.719281Z","iopub.execute_input":"2022-05-02T15:38:39.719561Z","iopub.status.idle":"2022-05-02T15:38:39.733526Z","shell.execute_reply.started":"2022-05-02T15:38:39.719531Z","shell.execute_reply":"2022-05-02T15:38:39.732607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Normalising Images**\n\nWhy do we normalize images in deep learning?\n\nWhen using the image as it is and passing through a Deep Neural Network, the computation of high numeric values may become more complex. To reduce this we can normalize the values to range from 0 to 1. In this way, the numbers will be small and the computation becomes easier and faster.\n\nReference- https://medium.com/analytics-vidhya/a-tip-a-day-python-tip-8-why-should-we-normalize-image-pixel-values-or-divide-by-255-4608ac5cd26a","metadata":{}},{"cell_type":"code","source":"def process_images(image):\n    # Normalize images to have a mean of 0 and standard deviation of 1\n    image = tf.image.per_image_standardization(image)\n    # Resize images from 32x32 to 277x277\n    image = tf.image.resize(image, (227,227))\n    return image","metadata":{"execution":{"iopub.status.busy":"2022-05-02T15:38:39.734828Z","iopub.execute_input":"2022-05-02T15:38:39.735108Z","iopub.status.idle":"2022-05-02T15:38:39.743562Z","shell.execute_reply.started":"2022-05-02T15:38:39.735081Z","shell.execute_reply":"2022-05-02T15:38:39.742568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = process_images(x_train)\nx_test = process_images(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T15:38:39.74513Z","iopub.execute_input":"2022-05-02T15:38:39.745442Z","iopub.status.idle":"2022-05-02T15:40:23.888457Z","shell.execute_reply.started":"2022-05-02T15:38:39.745386Z","shell.execute_reply":"2022-05-02T15:40:23.887029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Converting to an np array**\n\nNumPy arrays are faster and more compact than Python lists. An array consumes less memory and is convenient to use. NumPy uses much less memory to store data and it provides a mechanism of specifying the data types. This allows the code to be optimized even further.","metadata":{}},{"cell_type":"code","source":"x_train = np.array(x_train).reshape(-1, 227, 227, 3)\ny_train = np.array(y_train)\nx_test = np.array(x_test).reshape(-1, 227, 227, 3)\ny_test = np.array(y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T15:40:23.890776Z","iopub.execute_input":"2022-05-02T15:40:23.891107Z","iopub.status.idle":"2022-05-02T15:40:24.865307Z","shell.execute_reply.started":"2022-05-02T15:40:23.891066Z","shell.execute_reply":"2022-05-02T15:40:24.864523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Validating on Data(20% of training data)","metadata":{}},{"cell_type":"code","source":"x_validate = x_train[:520]\nx_train = x_train[521:]\ny_validate = y_train[:520]\ny_train = y_train[521:]","metadata":{"execution":{"iopub.status.busy":"2022-05-02T15:40:24.86641Z","iopub.execute_input":"2022-05-02T15:40:24.866641Z","iopub.status.idle":"2022-05-02T15:40:24.871715Z","shell.execute_reply.started":"2022-05-02T15:40:24.866613Z","shell.execute_reply":"2022-05-02T15:40:24.870881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Building the model**","metadata":{}},{"cell_type":"markdown","source":" Keras implementation of the AlexNet CNN architecture.","metadata":{}},{"cell_type":"code","source":"model = keras.models.Sequential([\n    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3)),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    keras.layers.Flatten(),\n    keras.layers.Dense(4096, activation='relu', input_shape=(227,227,3)),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(4096, activation='relu', input_shape=(227,227,3)),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(10, activation='softmax', input_shape=(227,227,3))\n])","metadata":{"execution":{"iopub.status.busy":"2022-05-02T15:40:24.873271Z","iopub.execute_input":"2022-05-02T15:40:24.873815Z","iopub.status.idle":"2022-05-02T15:40:26.465374Z","shell.execute_reply.started":"2022-05-02T15:40:24.873767Z","shell.execute_reply":"2022-05-02T15:40:26.464446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.optimizers.SGD(learning_rate=0.001), metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T15:40:26.468067Z","iopub.execute_input":"2022-05-02T15:40:26.468263Z","iopub.status.idle":"2022-05-02T15:40:26.494582Z","shell.execute_reply.started":"2022-05-02T15:40:26.468238Z","shell.execute_reply":"2022-05-02T15:40:26.493624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fitting the model to our dataset","metadata":{}},{"cell_type":"markdown","source":"**Using callbacks() from Keras to decide optimal epochs**\n\nkeras.callbacks.callbacks.EarlyStopping()\nEither loss/accuracy values can be monitored by Early stopping call back function. If the loss is being monitored, training comes to halt when there is an increment observed in loss values. Or, If accuracy is being monitored, training comes to halt when there is decrement observed in accuracy values.","metadata":{}},{"cell_type":"code","source":"from keras import callbacks\nearlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",mode =\"min\", patience = 5,restore_best_weights = True)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T15:40:26.496401Z","iopub.execute_input":"2022-05-02T15:40:26.496693Z","iopub.status.idle":"2022-05-02T15:40:26.501319Z","shell.execute_reply.started":"2022-05-02T15:40:26.496653Z","shell.execute_reply":"2022-05-02T15:40:26.500509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit the model\nhistory = model.fit(x_train,y_train, epochs=25, validation_data = (x_validate,y_validate),callbacks =[earlystopping])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-02T15:40:26.502995Z","iopub.execute_input":"2022-05-02T15:40:26.50327Z","iopub.status.idle":"2022-05-02T16:17:53.833756Z","shell.execute_reply.started":"2022-05-02T15:40:26.503232Z","shell.execute_reply":"2022-05-02T16:17:53.832963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T16:17:53.835215Z","iopub.execute_input":"2022-05-02T16:17:53.836076Z","iopub.status.idle":"2022-05-02T16:18:04.778493Z","shell.execute_reply.started":"2022-05-02T16:17:53.836027Z","shell.execute_reply":"2022-05-02T16:18:04.777586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test data (20% of kaggle dataset)","metadata":{}},{"cell_type":"code","source":"# getting predictions on test set.\npred=model.predict(x_test)\npred_digits=np.argmax(pred,axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T16:18:04.779567Z","iopub.execute_input":"2022-05-02T16:18:04.780044Z","iopub.status.idle":"2022-05-02T16:18:16.378236Z","shell.execute_reply.started":"2022-05-02T16:18:04.779997Z","shell.execute_reply":"2022-05-02T16:18:16.377619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Storing properly classified and misclassified indexes\ni=0\nprop_class=[]\nmis_class=[]\n\nfor i in range(len(y_test)):\n    if(y_test[i] ==pred_digits[i]):\n        prop_class.append(i)\n    else:\n        mis_class.append(i)\n        \nprint(\"Properly predicted: \" + str(len(prop_class)))\nprint(\"Misclassified: \" + str(len(mis_class)))\n   ","metadata":{"execution":{"iopub.status.busy":"2022-05-02T16:18:16.379356Z","iopub.execute_input":"2022-05-02T16:18:16.379663Z","iopub.status.idle":"2022-05-02T16:18:16.38554Z","shell.execute_reply.started":"2022-05-02T16:18:16.379637Z","shell.execute_reply":"2022-05-02T16:18:16.384735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualizing results**\n\nThe images are different in color due to normalization","metadata":{}},{"cell_type":"code","source":"count=0\nfig,ax=plt.subplots(4,2)\nfig.set_size_inches(15,15)\nfor i in range (4):\n    for j in range (2):\n        ax[i,j].imshow(x_test[prop_class[count]])\n        ax[i,j].set_title(\"Predicted : \"+str(pred_digits[prop_class[count]])+\"\\n\"+\"Actual : \"+str(np.argmax([y_test[prop_class[count]]])))\n        plt.tight_layout()\n        count+=1\n","metadata":{"execution":{"iopub.status.busy":"2022-05-02T16:18:16.386658Z","iopub.execute_input":"2022-05-02T16:18:16.386879Z","iopub.status.idle":"2022-05-02T16:18:18.561817Z","shell.execute_reply.started":"2022-05-02T16:18:16.386837Z","shell.execute_reply":"2022-05-02T16:18:18.56099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Running the model on images taken from OWU Parking Lot**","metadata":{}},{"cell_type":"code","source":"\n\ntest_data_path = \"/kaggle/input/owu-images/\" #Loading image from url\nowu_img_data = []\nowu_img_np=[]\nfor owu_test_img in os.listdir(test_data_path):  \n   # print(owu_test_img)\n    owu_img_data.append(os.path.join(test_data_path,owu_test_img))\n    test_img_arr = cv2.imread(os.path.join(test_data_path,owu_test_img))\n    test_new_img_arr = cv2.resize(test_img_arr,(img_size,img_size))\n    test_img = process_images(test_new_img_arr)\n    test_img= tf.image.per_image_standardization(test_img) #added\n    test_img = np.array(test_img).reshape(-1, 227, 227, 3) #converting rgb values into np aaray\n    owu_img_np.append(test_img)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T17:01:23.960835Z","iopub.execute_input":"2022-05-02T17:01:23.961379Z","iopub.status.idle":"2022-05-02T17:01:28.255902Z","shell.execute_reply.started":"2022-05-02T17:01:23.961324Z","shell.execute_reply":"2022-05-02T17:01:28.255134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"owu_predictions=[]\nfor test_img in owu_img_np: \n        owu_pred=model.predict(test_img)\n        owu_pred_digits=np.argmax(owu_pred,axis=1)\n        owu_predictions.append(float(owu_pred_digits))\n        ","metadata":{"execution":{"iopub.status.busy":"2022-05-02T17:01:30.24042Z","iopub.execute_input":"2022-05-02T17:01:30.24131Z","iopub.status.idle":"2022-05-02T17:01:31.876013Z","shell.execute_reply.started":"2022-05-02T17:01:30.241259Z","shell.execute_reply":"2022-05-02T17:01:31.875362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Results**","metadata":{}},{"cell_type":"code","source":"owu_results = []\nfor pred in owu_predictions:\n    if(pred == 0):\n        owu_results.append(\"free\")\n    else:\n        owu_results.append(\"full\")\n","metadata":{"execution":{"iopub.status.busy":"2022-05-02T17:01:35.975202Z","iopub.execute_input":"2022-05-02T17:01:35.97593Z","iopub.status.idle":"2022-05-02T17:01:35.981083Z","shell.execute_reply.started":"2022-05-02T17:01:35.975882Z","shell.execute_reply":"2022-05-02T17:01:35.980335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create figure\nfig = plt.figure(figsize=(20, 10))\nk=0\nfor test_img in owu_img_data: \n    k = k+1\n    fig.add_subplot(5,4,k)\n    plt.imshow(imread(test_img))\n    plt.axis('off')\n    plt.title(owu_results[owu_img_data.index(test_img)])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T17:01:38.609456Z","iopub.execute_input":"2022-05-02T17:01:38.609734Z","iopub.status.idle":"2022-05-02T17:02:00.36667Z","shell.execute_reply.started":"2022-05-02T17:01:38.609698Z","shell.execute_reply":"2022-05-02T17:02:00.365796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}